"""
Промпты для LLM-узлов графа.

Используем ChatPromptTemplate из LangChain для:
- Типобезопасности
- Интеграции с chains (prompt | model)
- Поддержки streaming
"""

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# =============================================================================
# ROUTER PROMPT
# Определяет домен запроса пользователя
# =============================================================================

ROUTER_PROMPT = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """Ты — маршрутизатор запросов. Твоя задача — определить, к какому домену относится вопрос пользователя.

Доступные домены:
{domains_list}

Правила:
1. Если вопрос чётко относится к ОДНОМУ домену — верни его slug
2. Если вопрос может относиться к НЕСКОЛЬКИМ доменам — верни "clarify"
3. Если вопрос НЕ относится НИ К ОДНОМУ домену — верни "off_topic"

Отвечай ТОЛЬКО одним словом: slug домена, "clarify" или "off_topic".
НЕ объясняй своё решение, НЕ добавляй ничего лишнего.""",
        ),
        ("human", "{input}"),
    ]
)

# =============================================================================
# GENERATE PROMPT
# Генерация ответа в контексте домена
# =============================================================================

GENERATE_PROMPT = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """Ты — полезный ассистент. Отвечай на вопросы пользователя дружелюбно и информативно.

Домен: {domain}

Правила:
1. Отвечай кратко и по существу
2. Если не знаешь точного ответа — честно скажи об этом
3. НЕ упоминай, что ты AI или что у тебя есть база знаний
4. Общайся естественно, как эксперт в данной области

{context}""",
        ),
        MessagesPlaceholder(variable_name="history", optional=True),
        ("human", "{input}"),
    ]
)
